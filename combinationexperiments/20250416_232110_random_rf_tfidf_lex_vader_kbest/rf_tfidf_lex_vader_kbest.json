{
  "experiment_setup": {
    "config": {
      "classifier_type": "rf",
      "embedding_type": "tfidf",
      "use_select_kbest": true,
      "brand_removal": true,
      "use_lexical_syntactic": true,
      "use_vader_sentiment": true,
      "use_smote": false,
      "use_scaler": false,
      "use_lda": false,
      "save_interesting_articles": false,
      "use_bias_features": false,
      "lexical_csv_path": "precomputed_lexical_custom.csv",
      "sentiment_csv_path": "precomputed_sentiment_custom.csv",
      "bias_csv_path": "precomputed_bias_custom.csv",
      "results_dir": "experiments/rf/tfidf_kbest_brand_lex_vader"
    },
    "best_params": {
      "clf__class_weight": "balanced",
      "clf__max_depth": 15,
      "clf__min_samples_leaf": 1,
      "clf__min_samples_split": 5,
      "clf__n_estimators": 500,
      "features__text__vectorizer__max_df": 0.8,
      "features__text__vectorizer__max_features": 5000,
      "features__text__vectorizer__min_df": 1,
      "features__text__vectorizer__ngram_range": [
        1,
        2
      ],
      "select__k": 637,
      "select__score_func": "f_classif"
    },
    "best_cv_score": 0.6575679800164007,
    "split_mode": "random"
  },
  "performance_summary": {
    "test_metrics": {
      "accuracy": 0.6176923076923077,
      "mae": 0.6030769230769231,
      "macro_f1": 0.6143870890407227,
      "macro_precision": 0.6115373316614625,
      "macro_recall": 0.6276730762077852,
      "weighted_f1": 0.6123291313871,
      "weighted_precision": 0.6151741641201487,
      "weighted_recall": 0.6176923076923077
    },
    "test_confusion_matrix": [
      [
        186,
        54,
        162
      ],
      [
        11,
        233,
        55
      ],
      [
        125,
        90,
        384
      ]
    ],
    "test_confidence_mean": 0.4371274697351609,
    "test_confidence_std": 0.0622253059236799,
    "classification_report_dict": {
      "0": {
        "precision": 0.577639751552795,
        "recall": 0.4626865671641791,
        "f1-score": 0.5138121546961326,
        "support": 402.0
      },
      "1": {
        "precision": 0.6180371352785146,
        "recall": 0.7792642140468228,
        "f1-score": 0.6893491124260355,
        "support": 299.0
      },
      "2": {
        "precision": 0.6389351081530782,
        "recall": 0.6410684474123539,
        "f1-score": 0.64,
        "support": 599.0
      },
      "accuracy": 0.6176923076923077,
      "macro avg": {
        "precision": 0.6115373316614625,
        "recall": 0.6276730762077852,
        "f1-score": 0.6143870890407227,
        "support": 1300.0
      },
      "weighted avg": {
        "precision": 0.6151741641201487,
        "recall": 0.6176923076923077,
        "f1-score": 0.6123291313871,
        "support": 1300.0
      }
    },
    "classification_report_text": "              precision    recall  f1-score   support\n\n           0      0.578     0.463     0.514       402\n           1      0.618     0.779     0.689       299\n           2      0.639     0.641     0.640       599\n\n    accuracy                          0.618      1300\n   macro avg      0.612     0.628     0.614      1300\nweighted avg      0.615     0.618     0.612      1300\n"
  },
  "timing": {
    "run_time_seconds": 92.61404299736023,
    "run_time_minutes": 1.543567383289337
  },
  "analysis_info": {
    "train_class_distribution": {
      "2": 10240,
      "0": 9750,
      "1": 7988
    },
    "test_class_distribution": {
      "2": 599,
      "0": 402,
      "1": 299
    },
    "pred_class_distribution": {
      "2": 601,
      "1": 377,
      "0": 322
    },
    "class_0_avg_probability": 0.32061302917862927,
    "class_1_avg_probability": 0.32423574376275666,
    "class_2_avg_probability": 0.35515122705861407,
    "rf_avg_tree_depth": 15.0,
    "brand_removal_enabled": true
  }
}