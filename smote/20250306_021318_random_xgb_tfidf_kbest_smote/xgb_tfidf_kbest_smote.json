{
  "experiment_setup": {
    "config": {
      "classifier_type": "xgb",
      "embedding_type": "tfidf",
      "brand_removal": false,
      "use_select_kbest": true,
      "use_smote": true,
      "use_scaler": false,
      "use_lexical_syntactic": false,
      "use_vader_sentiment": false,
      "use_lda": false,
      "use_bias_features": false,
      "save_interesting_articles": false,
      "lexical_csv_path": "precomputed_lexical_default.csv",
      "sentiment_csv_path": "precomputed_sentiment_default.csv",
      "bias_csv_path": "precomputed_bias_default.csv"
    },
    "best_params": {
      "clf__colsample_bytree": 0.8,
      "clf__gamma": 0.1,
      "clf__learning_rate": 0.05,
      "clf__max_depth": 7,
      "clf__min_child_weight": 3,
      "clf__n_estimators": 200,
      "clf__subsample": 0.7,
      "features__text__vectorizer__max_df": 0.8,
      "features__text__vectorizer__max_features": 5000,
      "features__text__vectorizer__min_df": 1,
      "features__text__vectorizer__ngram_range": [
        1,
        2
      ],
      "select__k": 1548,
      "select__score_func": "chi2"
    },
    "best_cv_score": 0.7282871395022574,
    "split_mode": "random"
  },
  "performance_summary": {
    "test_metrics": {
      "accuracy": 0.6923076923076923,
      "mae": 0.4869230769230769,
      "macro_f1": 0.6960389656846248,
      "macro_precision": 0.6877156436837373,
      "macro_recall": 0.7107396890845186,
      "weighted_f1": 0.6910152299849199,
      "weighted_precision": 0.6953615037673937,
      "weighted_recall": 0.6923076923076923
    },
    "test_confusion_matrix": [
      [
        264,
        34,
        104
      ],
      [
        16,
        247,
        36
      ],
      [
        129,
        81,
        389
      ]
    ],
    "test_confidence_mean": 0.593813955783844,
    "test_confidence_std": 0.141509547829628,
    "classification_report_dict": {
      "0": {
        "precision": 0.6454767726161369,
        "recall": 0.6567164179104478,
        "f1-score": 0.6510480887792849,
        "support": 402.0
      },
      "1": {
        "precision": 0.6823204419889503,
        "recall": 0.8260869565217391,
        "f1-score": 0.7473524962178517,
        "support": 299.0
      },
      "2": {
        "precision": 0.7353497164461248,
        "recall": 0.6494156928213689,
        "f1-score": 0.6897163120567376,
        "support": 599.0
      },
      "accuracy": 0.6923076923076923,
      "macro avg": {
        "precision": 0.6877156436837373,
        "recall": 0.7107396890845186,
        "f1-score": 0.6960389656846248,
        "support": 1300.0
      },
      "weighted avg": {
        "precision": 0.6953615037673937,
        "recall": 0.6923076923076923,
        "f1-score": 0.6910152299849199,
        "support": 1300.0
      }
    },
    "classification_report_text": "              precision    recall  f1-score   support\n\n           0      0.645     0.657     0.651       402\n           1      0.682     0.826     0.747       299\n           2      0.735     0.649     0.690       599\n\n    accuracy                          0.692      1300\n   macro avg      0.688     0.711     0.696      1300\nweighted avg      0.695     0.692     0.691      1300\n"
  },
  "timing": {
    "run_time_seconds": 358.5582733154297,
    "run_time_minutes": 5.975971221923828
  },
  "analysis_info": {
    "train_class_distribution": {
      "2": 10240,
      "0": 9750,
      "1": 7988
    },
    "test_class_distribution": {
      "2": 599,
      "0": 402,
      "1": 299
    },
    "pred_class_distribution": {
      "2": 529,
      "0": 409,
      "1": 362
    },
    "class_0_avg_probability": 0.33131784200668335,
    "class_1_avg_probability": 0.31199344992637634,
    "class_2_avg_probability": 0.3566886782646179,
    "xgb_num_trees": 200
  }
}